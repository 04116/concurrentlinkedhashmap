#summary Frequently Asked Questions

== Acknowledgements ==
I'd like to thank everyone who has submitted bugs, feature requests, or has reviewed the algorithm/implementation.

Special thanks to (in no particular order):
 * Greg Luck, who provided valuable feedback based on his own testing.
 * Adam Zell, who wrote the build, code reviews, and finds interesting papers.
 * Bob Lane, whose performance and concurrency expertise was invaluable when exploring algorithmic ideas.

== Usage ==
* Should I use this data structure?

While a goal is to have a functional implementation that can be used, the primary motivation for its creation was exploratory. It serves as a means to better understand concurrent and lock free algorithms by experimenting with different techinques. A pragmatic approach would be to implement a known algorithm, but this would not be educational and therefore defeats this project's sole purpose.

The practicality of why one would need this data structure is an interesting question. The miss penalty of a cache will far outweigh the overhead of synchronization on a cache hit. If lock contention is the issue then much simpler approaches offer equivilant performance. Example acceptable solutions include (1) an eviction thread that is woken when a threshold is crossed, (2) an eviction queue, (3) a [http://java.sun.com/javase/6/docs/api/java/util/LinkedHashMap.html LinkedHashMap] guarded by a read/write lock, and (4) eviction based on statistical sampling.

If the application realizes a noticable performance gain by using this type of data structure, it most likely indicates that there is a design flaw. As memory is a very expensive resource, a layering of caches (memory, disk, etc) should provide an acceptable miss penalty. The scope of data should be limited when possible, such as through thread-local storage if used only by a single execution flow. Techniques like these should be leveraged so that the application's acceptable performance is not impacted by this type of data structure.

The primary value for using this data structure should be (1) as a performance buffer to provide time to fix the application's architecture; (2) to improve operational cost and aid in capacity planning. By having a higher performing application the costs can be reduced in cooling, server management, hardware, etc. This goal is achieved by aggregating many improvements.

This discussion is not to disway usage of this data structure or others like it. However, from a practical perspective it should have limited value. From a theoretical perspective it is a fun engineering exercise.

* Which eviction policy is recommended?

The _Second Chance Fifo_ policy provides both an excellent hit rate and concurrency performance. It is recommended as the primary policy.

If the _Least Recently Used_ policy is used then the amount of expected concurrency should be relatively small. This is because each operation requires reordering the list which creates contention at the tail. In practice the cost is acceptable, but in extreme usages this policy will have poor performance characteristics.

== Development ==
* Why are fields marked volatile with an [http://java.sun.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicReferenceFieldUpdater.html AtomicReferenceFieldUpdater] instead of using an [http://java.sun.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicReference.html AtomicReference]?

This was done based on a [http://cs.oswego.edu/pipermail/concurrency-interest/2007-March/003802.html recommendation] by Doug Lea in regards to [http://java.sun.com/javase/6/docs/api/java/util/concurrent/ConcurrentLinkedQueue.html ConcurrentLinkedQueue].

  The two choices have different tradeoffs. Using fieldUpdaters does have more per-call overhead, but in principle most of it is optimizable away, and on some platforms and some contexts, it often is. Using a separate [http://java.sun.com/javase/6/docs/api/java/util/concurrent/atomic/AtomicReference.html AtomicReference] in essence doubles the length of a list (every second indirection is just a pointer holding the real pointer). And for small nodes as used here, nearly doubles the footprint -- even a one-field object has object header etc overhead, and increases GC overhead. All in all, using fieldUpdaters in this case is the best choice, even though on some programs/platforms it might on average be a  little slower (and on others faster).

  -Doug